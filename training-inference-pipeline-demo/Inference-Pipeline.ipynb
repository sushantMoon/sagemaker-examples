{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1d8b93f-2cd2-4633-9de6-8298bc2af485",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RoleArn: arn:aws:iam::874163252636:role/service-role/AmazonSageMaker-ExecutionRole-20201201T202376\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import boto3\n",
    "import re\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from sagemaker import get_execution_role, session\n",
    "import pandas as pd\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "role = get_execution_role()\n",
    "print(\"RoleArn: {}\".format(role))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64ecd054-b8ed-46a7-9acc-6456780ec29c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo Bucket: sagemaker-ap-south-1-874163252636\n",
      "Inference Output uri: s3://sagemaker-ap-south-1-874163252636/sagemaker/demo-preprocess-custom-monitor-batch-transform/1682420795/transform-outputs\n",
      "Baseline data uri: s3://sagemaker-ap-south-1-874163252636/sagemaker/demo-preprocess-custom-monitor-batch-transform/1682420795/baseline/data\n",
      "Monitoring Report uri: s3://sagemaker-ap-south-1-874163252636/sagemaker/demo-preprocess-custom-monitor-batch-transform/1682420795/monitor-reports\n",
      "Training Job Name: pipelines-pz947y174s62-ModelTraining-m818UPms0R\n",
      "Model Artifacts: s3://sagemaker-ap-south-1-874163252636/sagemaker/demo-preprocess-custom-monitor-batch-transform/1682420795/model-artifacts/pipelines-pz947y174s62-ModelTraining-m818UPms0R/output/model.tar.gz\n",
      "Inference Input Uri: s3://sagemaker-ap-south-1-874163252636/sagemaker/demo-preprocess-custom-monitor-batch-transform/1682420795/inference-data/test_sample.csv\n"
     ]
    }
   ],
   "source": [
    "bucket = session.Session(boto3.Session()).default_bucket()\n",
    "\n",
    "print(\"Demo Bucket: {}\".format(bucket))\n",
    "# prefix = f\"sagemaker/demo-preprocess-custom-monitor-batch-transform/{int(time.time())}\" 1682420795\n",
    "prefix = f\"sagemaker/demo-preprocess-custom-monitor-batch-transform/1682420795\" \n",
    "\n",
    "\n",
    "# batch transform output\n",
    "s3_inference_output_uri = \"s3://{}/{}/transform-outputs\".format(bucket, prefix)\n",
    "\n",
    "# monitoring results for violations\n",
    "monitor_reports_prefix = \"{}/monitor-reports\".format(prefix)\n",
    "s3_monitor_report_uri = \"s3://{}/{}\".format(bucket, monitor_reports_prefix)\n",
    "\n",
    "# baseline dataset paths\n",
    "baseline_prefix = f\"{prefix}/baseline\"\n",
    "baseline_data_prefix = baseline_prefix + \"/data\"\n",
    "s3_baseline_data_uri = f\"s3://{bucket}/{baseline_data_prefix}\"   # this has to come from training pipeline\n",
    "\n",
    "# model artifacts\n",
    "s3_model_artifacts_uri = 's3://sagemaker-ap-south-1-874163252636/sagemaker/demo-preprocess-custom-monitor-batch-transform/1682420795/model-artifacts/pipelines-pz947y174s62-ModelTraining-m818UPms0R/output/model.tar.gz'\n",
    "\n",
    "# test data\n",
    "s3_inference_data_uri = f\"s3://{bucket}/{prefix}/inference-data/test_sample.csv\"     # needs to come from the developer\n",
    "\n",
    "print(f\"Inference Output uri: {s3_inference_output_uri}\")\n",
    "print(f\"Baseline data uri: {s3_baseline_data_uri}\")\n",
    "print(f\"Monitoring Report uri: {s3_monitor_report_uri}\")\n",
    "print(f\"Training Job Name: {training_job_name}\")\n",
    "print(f\"Model Artifacts: {s3_model_artifacts_uri}\")\n",
    "print(f\"Inference Input Uri: {s3_inference_data_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e7f2906-1be4-4253-9429-4c3230d164d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "from sagemaker.workflow.parameters import ParameterString\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "from sagemaker.image_uris import retrieve\n",
    "from sagemaker.transformer import Transformer\n",
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.inputs import CreateModelInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac558b51-e881-4dd2-b42e-618cd0cce19f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_session = PipelineSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc053a9-2629-4061-aa2a-ecf4bc5c09a8",
   "metadata": {},
   "source": [
    "inference/testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51bfe6e2-3155-4153-ab26-1019c9a5dd5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: test_data/test_sample.csv to s3://sagemaker-ap-south-1-874163252636/sagemaker/demo-preprocess-custom-monitor-batch-transform/1682420795/inference-data/test_sample.csv\n",
      "2023-05-02 18:45:51      28734 test_sample.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp test_data/test_sample.csv {s3_inference_data_uri}\n",
    "!aws s3 ls {s3_inference_data_uri}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e0c591e-ce51-4de6-9286-cc08c3d1b73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_input_data = ParameterString(\n",
    "    name=\"BaselineData\", \n",
    "    default_value=s3_baseline_data_uri\n",
    ")\n",
    "\n",
    "model_location = ParameterString(\n",
    "    name='ModelLocation',\n",
    "    default_value=s3_model_artifacts_uri\n",
    ")\n",
    "\n",
    "inference_input_data = ParameterString(\n",
    "    name=\"InferenceData\", \n",
    "    default_value=s3_inference_data_uri\n",
    ")\n",
    "\n",
    "monitor_output = ParameterString(\n",
    "    name=\"MonitorOutput\", \n",
    "    default_value=s3_monitor_report_uri\n",
    ")\n",
    "\n",
    "inference_output = ParameterString(\n",
    "    name=\"InferenceOutput\", \n",
    "    default_value=s3_inference_output_uri\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4abb2d0-7e8a-4033-8f82-d106e2fa18b9",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9472bf38-34a3-4831-a74f-fe68653de77a",
   "metadata": {},
   "source": [
    "create the script that is going to do the preprocessing, then define the script object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6584c618-57c0-4784-a98b-52b44a33dd88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p inference_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3757091-27d4-4a0a-b76e-6c5083a21ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference_code/preprocess.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference_code/preprocess.py\n",
    "import argparse\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "subprocess.check_call([\n",
    "    sys.executable, \"-m\", \"pip\", \"install\", \"-r\",\n",
    "    \"/opt/ml/processing/input/code/custom_packages/requirements.txt\",\n",
    "])\n",
    "\n",
    "base_dir = '/opt/ml/processing'\n",
    "\n",
    "def preprocess(data):\n",
    "    # do some pre-processing\n",
    "    return data\n",
    "\n",
    "def main(args):\n",
    "    # read inference data for preprocessing from {base_dir}/input\n",
    "    data = pd.read_csv(f'{base_dir}/input/{args.file_name}', header=None)\n",
    "    processed_data = preprocess(data)\n",
    "    # store the inference ready processed data ta {base_dir}/output\n",
    "    processed_data.to_csv(f'{base_dir}/output/inference_processed_data.csv', header=False, index=False)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--file_name', help='file name for preprocessing')\n",
    "    args = parser.parse_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceec509d-fbea-4495-848d-f9c736c784f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sagemaker/workflow/pipeline_context.py:273: UserWarning: Running within a PipelineSession, there will be No Wait, No Logs, and No Job being started.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "framework_version = \"1.2-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(source=inference_input_data, destination=\"/opt/ml/processing/input\"),\n",
    "        ProcessingInput(source='custom_packages/', destination=\"/opt/ml/processing/input/code/custom_packages/\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"output\", source=\"/opt/ml/processing/output\")\n",
    "    ],\n",
    "    code=\"inference_code/preprocess.py\",\n",
    "    arguments=['--file_name', 'test_sample.csv']\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(name=\"InferencePreProcessing\", step_args=processor_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1c5fa5-4e6e-4296-bba7-64d3062c0645",
   "metadata": {},
   "source": [
    "### Batch Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b308ff1-8263-4852-8ac9-e0b6ca36aa57",
   "metadata": {},
   "source": [
    "first we create the model object and then use it to do the batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e17d9eb-55f2-49e4-8a18-75370036d867",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference_code/inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference_code/inference.py\n",
    "import argparse\n",
    "import os\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from io import StringIO\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model = xgb.XGBClassifier()\n",
    "    model.load_model(os.path.join(model_dir,\"model.json\"))\n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "input_fn\n",
    "    request_body: The body of the request sent to the model.\n",
    "    request_content_type: (string) specifies the format/variable type of the request\n",
    "\"\"\"\n",
    "def input_fn(request_body, request_content_type):\n",
    "    if request_content_type == \"text/csv\":\n",
    "        data = pd.read_csv(StringIO(request_body), header=None, index_col=False)\n",
    "        return data\n",
    "    else:\n",
    "        raise ValueError(\"This model only supports text/csv input\")\n",
    "\n",
    "\"\"\"\n",
    "predict_fn\n",
    "    input_data: returned array from input_fn above\n",
    "    model (sklearn model) returned model loaded from model_fn above\n",
    "\"\"\"\n",
    "def predict_fn(input_data, model):\n",
    "    return model.predict(input_data)\n",
    "\n",
    "\"\"\"\n",
    "output_fn\n",
    "    prediction: the returned value from predict_fn above\n",
    "    content_type: the content type the endpoint expects to be returned. Ex: JSON, string\n",
    "\"\"\"\n",
    "def output_fn(prediction, content_type):\n",
    "    response = '\\n'.join([str(x) for x in prediction.tolist()])\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2fbe78f-e34e-4230-b279-1103a7e21473",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_uri = retrieve(framework='sklearn', version='1.2-1', region=region)\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=model_location, \n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    "    source_dir='inference_code',\n",
    "    entry_point='inference.py',\n",
    "    dependencies=['custom_packages/requirements.txt'] \n",
    ")\n",
    "\n",
    "load_model_step = ModelStep(\n",
    "    name=\"LoadModelForInference\",\n",
    "    step_args=model.create(instance_type=\"ml.m5.xlarge\"),\n",
    "    # depends_on=[step_process]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce17bda7-c7fa-4ccc-a470-fa7f9ce85f25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    model_name=load_model_step.properties.ModelName,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    accept=\"text/csv\",\n",
    "    assemble_with=\"Line\",\n",
    "    strategy=\"MultiRecord\",\n",
    "    output_path=inference_output,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "transform_arg = transformer.transform(\n",
    "    step_process.properties.ProcessingOutputConfig.Outputs[\"output\"].S3Output.S3Uri,\n",
    "    content_type=\"text/csv\",\n",
    "    split_type=\"Line\",\n",
    "    join_source=\"Input\",\n",
    "    input_filter=\"$\",\n",
    "    output_filter=\"$\",\n",
    ")\n",
    "\n",
    "step_transform = TransformStep(\n",
    "    name=\"BatchTransform\", step_args=transform_arg,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16319220-f14d-45dd-bbac-31ddcba04a64",
   "metadata": {},
   "source": [
    "### Monitoring Data and Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b1be92-aa1a-4bb1-91d8-12015573cbc8",
   "metadata": {},
   "source": [
    "processing script for monitoring the data and predictions that is to be run post batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d524df3-c4bd-42d0-8fe3-185c68bb5d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting inference_code/monitor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference_code/monitor.py\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "subprocess.check_call([\n",
    "    sys.executable, \"-m\", \"pip\", \"install\", \"-r\",\n",
    "    \"/opt/ml/processing/input/code/custom_packages/requirements.txt\",\n",
    "])\n",
    "\n",
    "base_dir = '/opt/ml/processing'\n",
    "\n",
    "def monitor_data_and_model(baseline_data, inference_data):\n",
    "    # do some monitoring\n",
    "    return \"ALL GOOD\"\n",
    "\n",
    "def main():\n",
    "    # read baseline and inference data for monitoring data and model predictions {base_dir}/input\n",
    "    baseline_data = pd.read_csv(f'{base_dir}/input/baseline/training_processed_data.csv', header=None)\n",
    "    inference_data = pd.read_csv(f'{base_dir}/input/inference/inference_processed_data.csv.out', header=None)\n",
    "    \n",
    "    \n",
    "    result = monitor_data_and_model(baseline_data, inference_data)\n",
    "    # store the monitoring results ready processed data ta {base_dir}/output\n",
    "    with open(f'{base_dir}/output/monitoring_result.txt', 'w') as f:\n",
    "        f.write(result)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d970cf2f-c849-4a25-b311-4c285c424295",
   "metadata": {},
   "outputs": [],
   "source": [
    "framework_version = \"1.2-1\"\n",
    "\n",
    "monitor_sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    instance_count=1,\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "monitor_args = monitor_sklearn_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(source=inference_output, destination=\"/opt/ml/processing/input/inference\"),\n",
    "        ProcessingInput(source=baseline_input_data, destination=\"/opt/ml/processing/input/baseline\"),\n",
    "        ProcessingInput(source='custom_packages/', destination=\"/opt/ml/processing/input/code/custom_packages/\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(source=\"/opt/ml/processing/output\", destination=monitor_output)\n",
    "    ],\n",
    "    code=\"inference_code/monitor.py\"\n",
    ")\n",
    "\n",
    "step_monitor = ProcessingStep(name=\"DataAndModelMonitoring\", step_args=monitor_args, depends_on=[step_transform])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08946ef3-da20-4c8f-9514-7bee585de88e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline_name = f\"InferencePipeline\"\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        baseline_input_data,\n",
    "        model_location,\n",
    "        inference_input_data,\n",
    "        monitor_output,\n",
    "        inference_output,\n",
    "    ],\n",
    "    steps=[step_process, load_model_step, step_transform, step_monitor],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22fa2aee-59f6-4f8d-9562-045bdc473638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)\n",
    "execution = pipeline.start()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-south-1:394103062818:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
